{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Bottleneck model concept recall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.pardir, 'src')))\n",
    "\n",
    "from policy import ConceptNet\n",
    "from jem import data_utils\n",
    "\n",
    "model_name = 'net'\n",
    "session_name =  'falcon'\n",
    "board_size = 5\n",
    "nr_of_concepts = data_utils.get_number_of_concepts()\n",
    "\n",
    "benchmark_model_path = \"../models/cbm/conceptnet.keras\"\n",
    "\n",
    "agents_to_sample = [0, 10, 20, 60, 100, 500]\n",
    "cases_to_sample = 1000\n",
    "\n",
    "full_model_path = f\"../models/saved_sessions/conceptnet/board_size_{board_size}/{session_name}/\"\n",
    "\n",
    "def load_model(full_name, model_name, epoch):\n",
    "    model_path = full_name + model_name + \"_\" + str(epoch) + \".keras\"\n",
    "    model = ConceptNet(board_size, model_path)\n",
    "    return model\n",
    "\n",
    "agents = [load_model(full_model_path, model_name, epoch) for epoch in agents_to_sample]\n",
    "\n",
    "model = ConceptNet(board_size, nr_of_concepts, model_path=benchmark_model_path)\n",
    "\n",
    "states, concepts = data_utils.generate_concept_one_hot_encodings(agents, cases_to_sample, board_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the accuracy of the concept bottleneck output\n",
    "concepts_pred = model.predict_concepts(states)\n",
    "\n",
    "accuracy = accuracy_score(concepts, concepts_pred)\n",
    "print(f'Accuracy of bottleneck layer: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_gt_dict = data_utils.concept_functions_to_dict()\n",
    "concepts_pred_dict = data_utils.concept_functions_to_dict()\n",
    "\n",
    "\n",
    "# Plot the accuracy of each individual concept in the bottleneck layer\n",
    "for i, concept in enumerate(concepts):\n",
    "    # Find the index with the highest value in the prediction\n",
    "    pred = concepts_pred[i]\n",
    "    pred_idx = pred.argmax()\n",
    "    # Find all the indices where the concept is 1\n",
    "    concept_idx = concept.argmax()\n",
    "\n",
    "    concepts_gt_dict[concept_idx] += 1\n",
    "    concepts_pred_dict[pred_idx] += 1\n",
    "\n",
    "# Plot the concepts_gt_dict and concepts_pred_dict\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(len(concepts_gt_dict.keys()))\n",
    "bar_width = 0.35\n",
    "\n",
    "rects1 = ax.bar(index, concepts_gt_dict.values(), bar_width, label='Ground truth')\n",
    "rects2 = ax.bar(index + bar_width, concepts_pred_dict.values(), bar_width, label='Prediction')\n",
    "\n",
    "ax.set_xlabel('Concept')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Concepts')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(concepts_gt_dict.keys())\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "go-xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
