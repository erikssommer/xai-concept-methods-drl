# MCTS config
episodes: 1500
simulations: 100 # m
epsilon: 1 # rollout
epsilon_decay: 0 # 0.002
sigma: 0 # critic
sigma_decay: 0.001
alpha: 0.1 # Selecting move randomly, but weighted by the distribution (0 = argmax, 1 = probablistic)
alpha_decay: 0.0007
c: 1 # Exploration constant
nondet_plies: 8 # Number of plies to use for non-deterministic playouts

# Neural Network config
resnet: false
resnet_blocks: 3 # n
resnet_filters: 64 # f
convnet_filters: 32 # f
nr_of_anets: 10 # m
learning_rate: 0.001
move_cap: 200
pre_trained: false # Remember to set sigma and epsilon to 0 for faster training
pre_trained_path: ../models/pre_trained/board_size_5/

# Replay buffer config
rbuf_size: 2048 # Single process (2048)
rbuf_cap: 10000 # Multi process
sample_ratio: 0.5 # 50% chance of adding case to replay buffer, helps with overfitting
batch_size: 512 # 512
clear_rbuf: false

# Tensorboard config
log_dir: tensorboard_logs
log_name: go

# AlphaZero config
rl_canonical: true
rl_zero: false
rl_uct: false

# GO config
board_size: 5 # k
komi: 0.5 # gives white a bonus of x points at the end of the game due to black going first
canonical_board: false

# Threads
multi_process: false
nr_of_threads: 4
epochs: 10
epoch_skip: 0

# System
use_gpu: false

# Debug config
render: false
plot: false

# Topp config
nr_of_topp_games: 2 # g
