# MCTS config
episodes: 10000 # Single process
episodes_per_epoch: 2 # Multi process
simulations: 100 # m
c: 1.3 # Exploration constant
non_det_moves: 5 # Number of plies to use for non-deterministic playouts
epochs: 1000
epoch_skip: 0

# Neural Network config
resnet: true
resnet_filters: 128 # f
convnet_filters: 64 # f
nr_of_anets: 10 # m
save_intervals: [5, 10, 15, 20, 40, 60, 80, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]
learning_rate: 0.001
end_learning_rate: 0.0001
decay_steps: 10000
pre_trained: false # Remember to set sigma and epsilon to 0 for faster training
pre_trained_path: ../models/pre_trained/board_size_5/

# Replay buffer config
rbuf_size: 2048 # Single process (2048)
rbuf_cap: 20000 # Multi process
sample_ratio: 0.4 # 40% chance of adding case to replay buffer, helps with overfitting
batch_size: 128 # 512
clear_rbuf: false

# GO config
board_size: 5 # k
komi: 9.5 # gives white a bonus of x points at the end of the game due to black going first
move_cap: 120

# Debug config
render: false
plot: false

# Topp config
nr_of_topp_games: 2 # g

# Reward function config
reward_function: "zero_sum" # zero_sum, "concept_fn" or "jem"
